{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "## From Graph+AI World 2020 Conference\n",
    "This notebook contains the genre classification Graph Convolutional Neural Network for the Graph+AI World session From Dataframes to Graph: Data Science with pyTigerGraph by Parker Erickson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using backend: pytorch\n"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pyTigerGraph as tg\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TigerGraph Cloud Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading gsql client Jar\nDownloading SSL Certificate\n"
    }
   ],
   "source": [
    "conn = tg.TigerGraphConnection(\"https://musicgraph.i.tgcloud.io\", version=\"3.0.5\", graphname=\"musicGraph\")\n",
    "conn.apiToken = conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "========================\nTrying version: v3_0_5\nConnecting to musicgraph.i.tgcloud.io:14240\nWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\nIf there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\nThe query mainGenres has been added!\nStart installing queries, about 1 minute ...\nmainGenres query: curl -X GET 'https://127.0.0.1:9000/query/musicGraph/mainGenres'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\n"
    }
   ],
   "source": [
    "print(conn.gsql('''\n",
    "                CREATE QUERY mainGenres() FOR GRAPH musicGraph {\n",
    "                    types = {Genre.*};\n",
    "                    genres = SELECT t FROM types:g-(parentGenre:e)->Genre:t WHERE g.Title == \"\";\n",
    "                    PRINT genres;\n",
    "                }\n",
    "                \n",
    "                INSTALL QUERY mainGenres'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "========================\nTrying version: v3_0_5\nConnecting to musicgraph.i.tgcloud.io:14240\nWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\nIf there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\nThe query artistGenre has been added!\nStart installing queries, about 1 minute ...\nartistGenre query: curl -X GET 'https://127.0.0.1:9000/query/musicGraph/artistGenre'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\n"
    }
   ],
   "source": [
    "print(conn.gsql('''\n",
    "                CREATE QUERY artistGenre(/* Parameters here */) FOR GRAPH musicGraph SYNTAX v2{ \n",
    "                    MaxAccum<VERTEX<Genre>> @genre;\n",
    "                    types = {Genre.*};\n",
    "                    genres = SELECT t FROM types:g-(parentGenre>:e)-Genre:t WHERE g.Title == \"\";\n",
    "                    PRINT genres;\n",
    "                    artistGenres = SELECT a FROM Artist:a-(:e)-Track:t-(:e2)-genres:g ACCUM a.@genre = g;\n",
    "                    PRINT artistGenres;\n",
    "                }\n",
    "\n",
    "                INSTALL QUERY artistGenre'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "========================\nTrying version: v3_0_5\nConnecting to musicgraph.i.tgcloud.io:14240\nWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\nIf there is any relative path, it is relative to <System.AppRoot>/dev/gdk/gsql\nThe query artistLinks has been added!\nStart installing queries, about 1 minute ...\nartistLinks query: curl -X GET 'https://127.0.0.1:9000/query/musicGraph/artistLinks'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\n"
    }
   ],
   "source": [
    "print(conn.gsql('''\n",
    "                CREATE QUERY artistLinks(/* Parameters here */) FOR GRAPH musicGraph SYNTAX v2{ \n",
    "                    TYPEDEF TUPLE <VERTEX src, VERTEX dest> TUPLE_RECORD;\n",
    "                    SetAccum<TUPLE_RECORD> @@edges;\n",
    "                    //result = SELECT tgt FROM Artist:s-(:e1)-:mid-(:e2)-Artist:tgt WHERE s != tgt\n",
    "                    //        ACCUM @@edges += TUPLE_RECORD(s, tgt);\n",
    "                    res = SELECT tgt FROM Artist:s-(:e1)-Track:mid1-(:e2)-Album:mid2-(:e3)-Track:mid3-(:e4)-Artist:tgt WHERE s!= tgt\n",
    "                            ACCUM @@edges += TUPLE_RECORD(s, tgt);\n",
    "                    PRINT @@edges;\n",
    "                }\n",
    "                \n",
    "                INSTALL QUERY artistLinks'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Edges Between Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(x[\"src\"], x[\"dest\"]) for x in conn.runInstalledQuery(\"artistLinks\")[0][\"@@edges\"]]\n",
    "edges = random.choices(edges, k=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('5102', '2209'),\n ('24128', '24120'),\n ('14774', '8429'),\n ('7616', '9272'),\n ('10312', '14234')]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "edges[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DGL Graph\n",
    "Convert the list of edges into a graph that DGL, the machine learning library we are using, can interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allNodes = list(conn.getVertexDataframe(\"Artist\")[\"v_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Edges:  5000\n[(11619, 15542), (10162, 14818), (8903, 532), (2601, 1081), (1306, 14523)]\n"
    }
   ],
   "source": [
    "artistToNum = {} # translation dictionary for company name to number (for dgl)\n",
    "numToArtist = {} # translation dictionary for number to company name\n",
    "\n",
    "numericalNodes = []\n",
    "\n",
    "for i in range(0, len(allNodes)):\n",
    "    artistToNum[allNodes[i]] = i\n",
    "    numericalNodes.append(i)\n",
    "    artistToNum[i] = allNodes[i]\n",
    "\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    fromKey = artistToNum[result[0]]\n",
    "    toKey = artistToNum[result[1]]\n",
    "    return (fromKey, toKey)\n",
    "\n",
    "edges = [createEdgeList(thing) for thing in edges]\n",
    "print(\"Number of Edges: \", len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(numericalNodes)\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "G = dgl.DGLGraph(g) # Convert networkx graph to a graph that DGL can work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "16341"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features to Vertices\n",
    "Currently, we just one-hot encode the vertices in the graph to give them unique features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
    }
   ],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "print(G.nodes[2].data['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters and Build GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the message and reduce function\n",
    "# NOTE: We ignore the GCN's normalization constant c_ij for this tutorial.\n",
    "def gcn_message(edges):\n",
    "    # The argument is a batch of edges.\n",
    "    # This computes a (batch of) message called 'msg' using the source node's feature 'h'.\n",
    "    return {'msg' : edges.src['h']}\n",
    "\n",
    "def gcn_reduce(nodes):\n",
    "    # The argument is a batch of nodes.\n",
    "    # This computes the new 'h' features by summing received 'msg' in each node's mailbox.\n",
    "    return {'h' : torch.sum(nodes.mailbox['msg'], dim=1)}\n",
    "\n",
    "# Define the GCNLayer module\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # g is the graph and the inputs is the input node features\n",
    "        # first set the node features\n",
    "        g.ndata['h'] = inputs\n",
    "        # trigger message passing on all edges\n",
    "        g.send(g.edges(), gcn_message)\n",
    "        # trigger aggregation at all nodes\n",
    "        g.recv(g.nodes(), gcn_reduce)\n",
    "        # get the result node features\n",
    "        h = g.ndata.pop('h')\n",
    "        # perform linear transformation\n",
    "        return self.linear(h)\n",
    "\n",
    "# Define a 2-layer GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_feats, hidden_size)\n",
    "        self.gcn2 = GCNLayer(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.gcn1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Labels for Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = [int(x[\"v_id\"]) for x in conn.runInstalledQuery(\"mainGenres\")[0][\"genres\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[14, 2, 21, 8, 4, 1235, 15, 20, 12, 38, 5, 10, 13, 9, 3, 17]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistGenres = {}\n",
    "\n",
    "for artist in conn.runInstalledQuery(\"artistGenre\")[1][\"artistGenres\"]:\n",
    "    if artist[\"v_id\"] in artistToNum.keys():\n",
    "        try:\n",
    "            artistGenres[int(artist[\"attributes\"][\"@genre\"])].append(artist[\"v_id\"])\n",
    "        except:\n",
    "            artistGenres[int(artist[\"attributes\"][\"@genre\"])] = [artist[\"v_id\"]]\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 128, len(genres)) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([artistToNum[artistGenres[x][-1]] for x in genres])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([x for x in range(0, len(genres))])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([3416,  427,  448,  444,  291,  440,  469,  183,  470,  478,  382,  461,\n         174,  305,  323,  468])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "labeled_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 | Loss: 2.773e+00\nEpoch 1 | Loss: 2.636e+00\nEpoch 2 | Loss: 2.553e+00\nEpoch 3 | Loss: 2.516e+00\nEpoch 4 | Loss: 2.476e+00\nEpoch 5 | Loss: 2.438e+00\nEpoch 6 | Loss: 2.409e+00\nEpoch 7 | Loss: 2.388e+00\nEpoch 8 | Loss: 2.371e+00\nEpoch 9 | Loss: 2.356e+00\nEpoch 10 | Loss: 2.340e+00\nEpoch 11 | Loss: 2.324e+00\nEpoch 12 | Loss: 2.308e+00\nEpoch 13 | Loss: 2.292e+00\nEpoch 14 | Loss: 2.277e+00\nEpoch 15 | Loss: 2.263e+00\nEpoch 16 | Loss: 2.251e+00\nEpoch 17 | Loss: 2.240e+00\nEpoch 18 | Loss: 2.232e+00\nEpoch 19 | Loss: 2.226e+00\nEpoch 20 | Loss: 2.221e+00\nEpoch 21 | Loss: 2.216e+00\nEpoch 22 | Loss: 2.213e+00\nEpoch 23 | Loss: 2.210e+00\nEpoch 24 | Loss: 2.207e+00\nEpoch 25 | Loss: 2.204e+00\nEpoch 26 | Loss: 2.201e+00\nEpoch 27 | Loss: 2.199e+00\nEpoch 28 | Loss: 2.197e+00\nEpoch 29 | Loss: 2.194e+00\nEpoch 30 | Loss: 2.192e+00\nEpoch 31 | Loss: 2.190e+00\nEpoch 32 | Loss: 2.188e+00\nEpoch 33 | Loss: 2.186e+00\nEpoch 34 | Loss: 2.184e+00\nEpoch 35 | Loss: 2.182e+00\nEpoch 36 | Loss: 2.181e+00\nEpoch 37 | Loss: 2.179e+00\nEpoch 38 | Loss: 2.177e+00\nEpoch 39 | Loss: 2.175e+00\nEpoch 40 | Loss: 2.174e+00\nEpoch 41 | Loss: 2.172e+00\nEpoch 42 | Loss: 2.171e+00\nEpoch 43 | Loss: 2.169e+00\nEpoch 44 | Loss: 2.168e+00\nEpoch 45 | Loss: 2.166e+00\nEpoch 46 | Loss: 2.165e+00\nEpoch 47 | Loss: 2.164e+00\nEpoch 48 | Loss: 2.162e+00\nEpoch 49 | Loss: 2.161e+00\nEpoch 50 | Loss: 2.160e+00\nEpoch 51 | Loss: 2.158e+00\nEpoch 52 | Loss: 2.157e+00\nEpoch 53 | Loss: 2.156e+00\nEpoch 54 | Loss: 2.155e+00\nEpoch 55 | Loss: 2.154e+00\nEpoch 56 | Loss: 2.153e+00\nEpoch 57 | Loss: 2.152e+00\nEpoch 58 | Loss: 2.151e+00\nEpoch 59 | Loss: 2.150e+00\nEpoch 60 | Loss: 2.149e+00\nEpoch 61 | Loss: 2.148e+00\nEpoch 62 | Loss: 2.147e+00\nEpoch 63 | Loss: 2.146e+00\nEpoch 64 | Loss: 2.145e+00\nEpoch 65 | Loss: 2.144e+00\nEpoch 66 | Loss: 2.143e+00\nEpoch 67 | Loss: 2.143e+00\nEpoch 68 | Loss: 2.142e+00\nEpoch 69 | Loss: 2.141e+00\nEpoch 70 | Loss: 2.140e+00\nEpoch 71 | Loss: 2.140e+00\nEpoch 72 | Loss: 2.139e+00\nEpoch 73 | Loss: 2.138e+00\nEpoch 74 | Loss: 2.137e+00\nEpoch 75 | Loss: 2.137e+00\nEpoch 76 | Loss: 2.136e+00\nEpoch 77 | Loss: 2.135e+00\nEpoch 78 | Loss: 2.135e+00\nEpoch 79 | Loss: 2.134e+00\nEpoch 80 | Loss: 2.134e+00\nEpoch 81 | Loss: 2.133e+00\nEpoch 82 | Loss: 2.132e+00\nEpoch 83 | Loss: 2.132e+00\nEpoch 84 | Loss: 2.131e+00\nEpoch 85 | Loss: 2.131e+00\nEpoch 86 | Loss: 2.130e+00\nEpoch 87 | Loss: 2.130e+00\nEpoch 88 | Loss: 2.129e+00\nEpoch 89 | Loss: 2.128e+00\nEpoch 90 | Loss: 2.128e+00\nEpoch 91 | Loss: 2.127e+00\nEpoch 92 | Loss: 2.127e+00\nEpoch 93 | Loss: 2.127e+00\nEpoch 94 | Loss: 2.126e+00\nEpoch 95 | Loss: 2.126e+00\nEpoch 96 | Loss: 2.125e+00\nEpoch 97 | Loss: 2.125e+00\nEpoch 98 | Loss: 2.124e+00\nEpoch 99 | Loss: 2.124e+00\n"
    }
   ],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600294407940",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}